% This file was created with Citavi 6.10.0.0

@inproceedings{Alam2021,
  author = {Alam, Shahidul and Ahmed, Mueed and Dax, Gabriel and Werner, Martin},
  title = {Change detection of Lake Starnberg, Germany using NDVI and Sentinel 2},
  booktitle = {Symposium f{\"u}r Angewandte Geoinformatik (AGIT'2021)},
  year = {2021}
}


@inproceedings{Dax2021,
  author = {Dax, Gabriel and Laass, Moritz and Werner, Martin},
  title = {Genetic Algorithm for Improved Transfer Learning Through Bagging Color-Adjusted Models},
  pages = {2612--2615},
  publisher = {IEEE},
  isbn = {978-1-6654-0369-6},
  booktitle = {2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS},
  year = {2021},
  doi = {10.1109/IGARSS47720.2021.9554380}
}


@article{Dax2021b,
  author = {Dax, Gabriel and Werner, Martin},
  year = {2021},
  title = {Information-optimal Abstaining for Reliable Classification of Building Functions},
  pages = {1--10},
  volume = {2},
  journal = {AGILE: GIScience Series},
  doi = {10.5194/agile-giss-2-1-2021}
}


@inproceedings{Dax2021c,
  author = {Dax, Gabriel and Werner, Martin},
  title = {Trajectory Similarity using Compression},
  pages = {169--174},
  publisher = {IEEE},
  isbn = {978-1-6654-2845-3},
  booktitle = {2021 22nd IEEE International Conference on Mobile Data Management (MDM)},
  year = {2021},
  doi = {10.1109/MDM52706.2021.00035}
}


@inproceedings{Dax2022,
  author = {Dax, Gabriel and Werner, Martin},
  title = {The Role of Compression in Spatial Computing},
  url = {https://www.geoinfo.uni-bonn.de/DGKGeoinfo2022/pdf-dokumente/09_DGKGeoinfo2022_DAX-WERNER_paper_2684.pdf},
  keywords = {Bloom filter;Compression;Deep Learning;Spatial Computing},
  booktitle = {PhD Colloquium of the DGK Section on Geoinformatics 2022},
  year = {2022},
  address = {Braunschweig}
}


@inproceedings{Denizoglu2022,
  author = {Denizoglu, Deniz Gaye and Dax, Gabriel and Nagarajan, Srilakshmi and Zhang, Ning and Werner, Martin},
  title = {Global Active Fire Detection -- Towards a SAR-enabled Multi-Sensor Global Monitoring System},
  booktitle = {Living Planet Symposium 2022},
  year = {2022}
}


@incollection{Ghiglione2021,
  author = {Ghiglione, Max and Raoofy, Amir and Dax, Gabriel and Furano, Gianluca and Wiest, Richard and Trinitis, Carsten and Werner, Martin and Schulz, Martin and Langer, Martin},
  title = {Machine Learning Application Benchmark for Satellite On-Board Data Processing},
  booktitle = {European Workshop on On-Board Data Processing},
  year = {2021},
  doi = {10.5281/zenodo.5520877}
}


@inproceedings{Ghiglione2022,
  author = {Ghiglione, Max and Serra, Vittorio and Raoofy, Amir and Dax, Gabriel and Trinitis, Carsten and Werner, Martin and Schulz, Martin and Furano, Gianluca},
  title = {Survey of frameworks for inference of neural networks in space data system},
  booktitle = {DASIA 2022},
  year = {2022}
}


@inproceedings{Gotzer2021,
  author = {G{\"o}tzer, Stephan and Laass, Moritz and Dax, Gabriel and Werner, Martin},
  title = {ObservaToriUM: A Simple Scalable Earth Observation Processing Engine},
  booktitle = {Symposium f{\"u}r Angewandte Geoinformatik (AGIT'2021)},
  year = {2021}
}


@inproceedings{Raoofy2022,
  author = {Raoofy, Amir and Dax, Gabriel and Serra, Vittorio and Ghiglione, Max and Werner, Martin and Trinitis, Carsten},
  title = {Benchmarking and feasibility aspects of machine learning in space systems},
  pages = {225--226},
  publisher = {ACM},
  isbn = {9781450393386},
  booktitle = {Proceedings of the 19th ACM International Conference on Computing Frontiers},
  year = {2022},
  address = {New York, NY, USA},
  doi = {10.1145/3528416.3530986}
}


@inproceedings{Werner2020,
  abstract = {In the last decades, environmental research has started to adopt a data-driven perspective enabled by huge sensor networks, satellite-based Earth observation, and almost ubiquitous Internet access. Some of these data-driven approaches are expected to make visions of a sustainable future come true. For example, by enabling societies to live in sustainable smart cities, or to feed the world with precision agriculture. Or by fighting environmental pollution or global deforestation with increased observational power. However, there is a serious gap between some of the current expectations put into data-driven techniques and the maturity of the field of spatial machine learning and artificial intelligence or computer science in general. We give a few examples of open research issues that computer science has to solve in order to make data-driven approaches to environmental sciences successful.},
  author = {Werner, Martin and Dax, Gabriel and Laass, Moritz},
  title = {Computational Challenges for Artificial Intelligence and Machine Learning in Environmental Research},
  booktitle = {INFORMATIK 2020},
  year = {2020},
  doi = {10.18420/inf2020{\textunderscore }95}
}


@inproceedings{Zeya2021,
  author = {Zeya, Syed Miftah and Theofanidis, Alexandros and Dax, Gabriel and Werner, Martin},
  title = {Forest and Vegetation Monitoring Using Sentinel-2 Imageryin the Northern Part of Democratic Republic of Congo},
  booktitle = {Proceedings of the 24th AGILE Conference on Geographic Information Science (AGILE'2021)},
  year = {2021}
}


@inproceedings{dlr138129,
  author = {Corneliu Octavian Dumitru and Gottfried Schwarz and Dongyang Ao and Gabriel Dax and Chandrabali Karmakar and Mihai Datcu},
  title = {Selection of Reliable Machine Learning Algorithms for Geophysical Applications},
  booktitle = {EGU 2020},
  year = {2020},
  month = {Mai},
  abstract = {During the last years, one could see a broad use of machine learning tools and applications. However, when we use these techniques for geophysical analyses, we must be sure that the obtained results are scientifically valid and allow us to derive quantitative outcomes that can be directly compared with other measurements.
Therefore, we set out to identify typical datasets that lend themselves well to geophysical data interpretation. To simplify this very general task, we concentrate in this contribution on multi-dimensional image data acquired by satellites with typical remote sensing instruments for Earth observation being used for the analysis for:
- Atmospheric phenomena (cloud cover, cloud characteristics, smoke and plumes, strong winds, etc.)
- Land cover and land use (open terrain, agriculture, forestry, settlements, buildings and streets, industrial and transportation facilities, mountains, etc.)
- Sea and ocean surfaces (waves, currents, ships, icebergs, coastlines, etc.)
- Ice and snow on land and water (ice fields, glaciers, etc.)
- Image time series (dynamical phenomena, their occurrence and magnitude, mapping techniques)
Then we analyze important data characteristics for each type of instrument. One can see that most selected images are characterized by their type of imaging instrument (e.g., radar or optical images), their typical signal-to-noise figures, their preferred pixel sizes, their various spectral bands, etc.
  As a third step, we select a number of established machine learning algorithms, available tools, software packages, required environments, published experiences, and specific caveats. The comparisons cover traditional {``}flat{''} as well as advanced {``}deep{''} techniques that have to be compared in detail before making any decision about their usefulness for geophysical applications. They range from simple thresholding to k-means, from multi-scale approaches to convolutional networks (with visible or hidden layers) and auto-encoders with sub-components from rectified linear units to adversarial networks.
Finally, we summarize our findings in several instrument / machine learning algorithm matrices (e.g., for active or passive instruments). These matrices also contain important features of the input data and their consequences, computational effort, attainable figures-of-merit, and necessary testing and verification steps (positive and negative examples). Typical examples are statistical similarities, characteristic scales, rotation invariance, target groupings, topic bagging and targeting (hashing) capabilities as well as local compression behavior.},
  keywords = {Machine learning, applications},
  url = {https://elib.dlr.de/138129/}
}


@incollection{dlr138139,
  title = {Active and Machine Learning for Earth Observation Image Analysis with Traditional and Innovative Approaches},
  pages = {207--231},
  publisher = {Springer Nature Switzerland AG},
  editor = {H. R. Arabnia and K. Daimi and R. Stahlbock and C. Soviany and L. Heilig and K. Brussau},
  journal = {Principles of Data Science},
  series = {Transactions on Computational Science and Computational Intelligence},
  author = {Corneliu Octavian Dumitru and Gottfried Schwarz and Gabriel Dax and Andrei Vlad and Dongyang Ao and Mihai Datcu},
  year = {2020},
  url = {https://elib.dlr.de/138139/},
  keywords = {machine learning, coastline detection, icebergs, sea-ice},
  abstract = {We demonstrate how established applications and tools for image classification and change detection can profit from advanced information theory together with automated quality control strategies. As a typical example, we deal with the task of coastline detection in satellite images; here, rapid and correct image interpretation is of utmost importance for riskless shipping and accurate event monitoring.
If we combine current machine learning algorithms with new approaches, we can see how current deep learning concepts can still be enhanced. Here, information theory paves the way towards interesting innovative solutions.
The validation of the proposed methods will be demonstrated on two target areas: the first one is the Danube Delta, which is the second largest river delta in Europe and is the best preserved one on the continent. Since 1991, the Danube Delta has been inscribed on the UNESCO World Heritage List due do its biological uniqueness. The second one is Belgica Bank in the north-east of Greenland which is an area of extensive fast land-locked ice that is ideal for monitoring seasonal variations of the ice cover and icebergs.}
}


@inproceedings{dlr130271,
  title = {SAR Change Detection in a General Case Using Normalized Compression Distance},
  author = {Gabriel Dax and Corneliu Octavian Dumitru and Gottfried Schwarz and Mihai Datcu},
  booktitle = {TerraSAR-X Science Team Meeting 2019},
  year = {2019},
  month = {Oktober},
  url = {https://elib.dlr.de/130271/},
  keywords = {Synthetic Aparture Radar, Normalized Compression Distance,Change Detection},
  abstract = {During the last decades, natural and human-made disasters had a strong impact on their surrounding areas, and also the development of cities changed the land cover of the affected areas. To detect these changes in a satellite image time series, a parameter-free unsupervised approach using Normalized Compression Distance (NCD) was used to calculate a binary change map. NCD is a distance measure where an extraction of features is not required; instead, this method can calculate the distance between two objects with respect to the context within an image using patches. This approach was used to detect changes in different regions of interest (e.g., the Danube Delta in Romania or Belgica Bank in Greenland) independently of a special scenario or a specific SAR satellite, which enables the use of parameter-free unsupervised change detection for different scenarios.}
}


@inproceedings{dlr130276,
  year = {2019},
  booktitle = {{\ensuremath{\Phi}}-week},
  month = {September},
  title = {No Feature Data Analytics: Compression Pattern Recognition},
  author = {Mihai Coca and Mihai Datcu and Gabriel Dax and Corneliu Octavian Dumitru and Gottfried Schwarz and Wei Yao},
  abstract = {Similarity matrix shows the similarity degree between each data pairs, it actually plays a core role in a number of dimensionality reduction methods, since the objective function builds upon this matrix. While compression-based similarity measures are effectively employed in applications on diverse data types as basically parameter free approach, a fast compression distance (FCD) metric has been proved to be able to achieve similar classification performance comparing with the Normalized Compression Distance (NCD) method, regarding small- to medium- size datasets [1].

The FCD is claimed as combining a fast speed without skipping the joint compression step which obtains better performance compared with NCD [2]. The idea behind is: the LZW algorithm extracts a dictionary D(x) from each image patch, and encode into a string x, in ascending order. The definition of FCD is defined as an operation which mainly takes account of the joint number of patterns within two dictionaries D(x) and D(y).

  In this research, we use FCD together with t-SNE to visualize a large semantic annotated TerraSAR-X dataset as a study case. The dataset contain image patches from 288 TerraSAR-X images with a total number of over 60,000 individual image patches.

  The visualizations represent the annotated semantic labels in such an intuitive way which helps us to better understand the relationships between their annotated semantics and how their actual similarities are in manifold space. Our obtained results show that the FCD based similarity matrix effectively provides us a fast yet performance preserved insights in high-dimensional datasets with a non-parametric distance metric. Via the visualization on TerraSAR-X dataset, we have gained quick intuition and better understanding of the connections between the annotated semantics and the relationships within the data which is revealed as similarities in manifold space. The visualization interpretation is based on a vega-style interactive tool, which allows user zoom in, zoom out for processing large amount of data points.

Change Detection methods are dependent on the extracted image features and measures of similarity used for the comparison of the observed scene at different time moment. The NCD has an important advantage; it does not use features and compares the intrinsic data information. The change detection is thus an un-polarized estimator for temporal changes. The method is validated on two areas with visible changes such as flooding and tsunami effects. The results are compared with the ground truth data.

The influence of natural disasters, as well as climate warming of the global environment increased in the past decades. Therefore, the detection of changes in a satellite image time series is a trivial task [3]. In order to do this, the calculation processes can be divided into several phases. The first represents the preprocessing, which includes an alignment of all images as well as the creation of patches in a region of interest. We propose here to use the Sentinel-1 SAR data. The second phase encloses the generation of a distance matrix of the patches from two images. In the last phase a threshold is applied to the created matrix, in order to show the changes in a binary way as binary change map (BCM). The results show that a compression-based approach is working with very good results on SAR data. Moreover, a visual evaluation of the resulting images shows that the compression-based approach detects the flooded areas within a region. Furthermore, if the input is reordered with the Burrows and Wheeler transformation [4], the resulting image is better in some areas that the base method. This shows the robustness of NCD.



  [1] C. Daniele and M. Datcu, {``}A fast compression-based similarity measure with applications to content-based image retrieval,{''} Journal of Visual Communication and ImageRepresentation, vol. 23, pp. 293{--}302, February 2012.

[2] M. Li, X. Chen, X. Li, Ma. B., and P.M.B. Vitanyi, {``}The similarity metric,{''} IEEE Transaction of Information Theory, vol. 50, pp. 3250{--}3264, 2004.

[3] M. Coca, A. Anghel, M. Datcu, {``}Normalized compression distance for SAR image change Detection{''}, pp. 1-3, 2018.

[4] R. Giancarlo, A. Restivo, M. Sciortino, {``}From first principles to the Burrows and Wheeler transform and beyond, via combinatorial optimization{''}, Elsevier Theoretical Computer Science, vol. 387, pp. 236-248, 2007.},
  url = {https://elib.dlr.de/130276/},
  keywords = {Data Analytics, No Feature, Pattern Recognition}
}


@inproceedings{dlr129121,
  author = {Corneliu Octavian Dumitru and Gabriel Dax and Gottfried Schwarz and Constantin Cazacu and Mihai Cristian Adamescu and Mihai Datcu},
  pages = {1--13},
  title = {Accurate Monitoring of the Danube Delta Dynamics using Copernicus Data},
  year = {2019},
  booktitle = {SPIE Remote Sensing},
  abstract = {In the following, we describe highly-automated image analysis approaches that help us classify satellite images, and allow us to monitor dynamical changes in image time series. We concentrated on flooding events within the Danube Delta as seen by the European Sentinel-1 and Sentinel-2 satellites, and describe systematic processing approaches to extract pre-defined categories from the image data (being either Synthetic Aperture Radar or multispectral images). One basic tool to monitor dynamical changes is to analyze and compare the compressibility of image patches using their Normalized Compression Distances. These distances can be converted into similarity matrices providing reliable maps of surface changes. The accuracy of these change maps was quantified for several typical test cases. In addition, we analyzed the performance of an alternative active learning approach, where Gabor filters and Weber local descriptors were used to extract features from image patches that were classified and semantically annotated. Then one can perform data analytics and generate maps based on the extracted semantic annotations; again, we used several representative test cases for benchmarking.},
  url = {https://elib.dlr.de/129121/},
  keywords = {Classification, change detection, Copernicus satellite data, coastline detection, Danube Delta, normalized compression distance, Sentinel-1, Sentinel-2.}
}

